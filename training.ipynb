{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model in DyNet\n",
    "In this tutorial, we will train a bag-of-words model to differentiate between negative and postive movie reviews using the movie review dataset from Cornell [(Pang and Lee 2004)](http://www.cs.cornell.edu/home/llee/papers/cutsent.home.html).\n",
    "\n",
    "## Simple data pre-processing\n",
    "Loading the negative and positive reviews into memory. This code uses only the first sentence in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "def load_data(directory):\n",
    "    l = [ ]\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"txt\"):\n",
    "            words = nltk.word_tokenize((open(directory + filename).readlines()[0]).lower())\n",
    "            l.append({\"id\" : filename, \"data\" : words})\n",
    "    return l\n",
    "\n",
    "negative_examples = load_data(\"neg/\")\n",
    "positive_examples = load_data(\"pos/\")\n",
    "\n",
    "print(\"num per class: negative \" + str(len(negative_examples)) + \"; positive \" + str(len(positive_examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(negative_examples[24][\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to split into a train/dev split. For this dataset, there are not traditional splits (prior work uses cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_examples = [ ]\n",
    "train_examples = [ ]\n",
    "\n",
    "import random\n",
    "random.shuffle(negative_examples)\n",
    "random.shuffle(positive_examples)\n",
    "\n",
    "for example in negative_examples:\n",
    "    example[\"label\"] = 0\n",
    "    randnum = random.random()\n",
    "    if randnum < 0.8:\n",
    "        train_examples.append(example)\n",
    "    else:\n",
    "        dev_examples.append(example)\n",
    "        \n",
    "for example in positive_examples:\n",
    "    example[\"label\"] = 1\n",
    "    randnum = random.random()\n",
    "    if randnum < 0.8:\n",
    "        train_examples.append(example)\n",
    "    else:\n",
    "        dev_examples.append(example)\n",
    "        \n",
    "print(\"lengths: train \" + str(len(train_examples)) + \"; dev \" + str(len(dev_examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(train_examples[0][\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a vocabulary list using the words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set([word for example in train_examples for word in example[\"data\"]])) + [\"UNK\"]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [vocab.index(word) for word in train_examples[0][\"data\"][:10] if word in vocab]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[vocab[index] for index in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at word frequencies in training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "d = defaultdict(int)\n",
    "wordlist = [word for example in train_examples for word in example[\"data\"]]\n",
    "for word in wordlist:\n",
    "    d[word] += 1\n",
    "plt.plot(range(len(d)), list(reversed(sorted(d.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now we can start building the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the ParameterCollection\n",
    "Our model will be a simple bag-of-words model with a single hidden layer. The model will have the following parameters:\n",
    "\n",
    "1. A `LookupParameters` object for the words in the data, which is of size len(vocab) x 64.\n",
    "2. A `Parameters` object for the hidden layer of size 64 x 64.\n",
    "3. A `Parameters` object for the hidden layer's biases of size 64 x 1.\n",
    "4. A `Parameters` object for the final layer of size 64 x 2.\n",
    "5. A `Parameters` object for the final layer's biases of size 2 x 1.\n",
    "\n",
    "We will show off a few things in this section:\n",
    "\n",
    "1. Naming parameters. This will make things a bit easier to debug if necessary.\n",
    "2. Initializing parameters using [`PyInitializer`](http://dynet.readthedocs.io/en/latest/python_ref.html#parameters-initializers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _dynet as dy\n",
    "dyparams = dy.DynetParams()\n",
    "dyparams.set_mem(2048)\n",
    "dyparams.set_autobatch(True)\n",
    "dyparams.init()\n",
    "\n",
    "pc = dy.ParameterCollection()\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_CLASSES = 2\n",
    "word_embeddings = pc.add_lookup_parameters((len(vocab), HIDDEN_SIZE), name=\"word-embeddings\")\n",
    "hidden_weights = pc.add_parameters((HIDDEN_SIZE, HIDDEN_SIZE), name=\"hidden-weights\", init=dy.NormalInitializer())\n",
    "hidden_biases = pc.add_parameters((HIDDEN_SIZE, 1), name=\"hidden-biases\", init=dy.NormalInitializer())\n",
    "final_weights = pc.add_parameters((HIDDEN_SIZE, NUM_CLASSES), name = \"final-weights\")\n",
    "final_biases = pc.add_parameters((NUM_CLASSES, 1), name = \"final-biases\")\n",
    "\n",
    "[(param.name(), param.shape()) for param in pc.lookup_parameters_list() + pc.parameters_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should implement a function that takes a single example and computes a set of scores over the two classes. This will later be used for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(example):\n",
    "    word_vectors = [ ]\n",
    "    \n",
    "    # First, get the word embeddings for every word in the data.\n",
    "    for word in example[\"data\"]:\n",
    "        if word in vocab:\n",
    "            word_vectors.append(word_embeddings[vocab.index(word)])\n",
    "        else:\n",
    "            word_vectors.append(word_embeddings[vocab.index(\"UNK\")])\n",
    "    \n",
    "    # Then get the average word embedding for the example.\n",
    "    embedding = dy.esum(word_vectors) / float(len(word_vectors))\n",
    "    \n",
    "    # Intermediate representation...\n",
    "    intermediate_value = hidden_weights * dy.reshape(embedding, (HIDDEN_SIZE, 1)) + hidden_biases\n",
    "    \n",
    "    # With a nonlinearity\n",
    "    intermediate_value = dy.tanh(intermediate_value)\n",
    "    \n",
    "    # Final probability distribution\n",
    "    scores = dy.transpose(final_weights) * intermediate_value  + final_biases\n",
    "    return scores\n",
    "\n",
    "dy.renew_cg()\n",
    "get_scores(train_examples[0]).value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: loss, prediction\n",
    "\n",
    "To get the loss for a particular example, we can simply use the [`dy.pickneglogsoftmax`](http://dynet.readthedocs.io/en/latest/python_ref.html#dynet.pickneglogsoftmax) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy.pickneglogsoftmax(get_scores(train_examples[0]), train_examples[0][\"label\"]).value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, let's write a simple function that will compute whether a prediction was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate(example):\n",
    "    prediction = np.argmax(get_scores(example).value())\n",
    "    return prediction == example[\"label\"]\n",
    "\n",
    "evaluate(train_examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Let's look at how training works for 20 examples. First we need to create an optimizer. Let's use the [Adam optimizer](http://dynet.readthedocs.io/en/latest/python_ref.html#dynet.AdamTrainer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "optimizer = dy.AdamTrainer(pc)\n",
    "\n",
    "epoch_start_time = time.time()\n",
    "\n",
    "for i, example in enumerate(train_examples[:20]):\n",
    "    dy.renew_cg()\n",
    "    loss = dy.pickneglogsoftmax(get_scores(example), example[\"label\"])\n",
    "    loss.forward()\n",
    "    loss.backward()\n",
    "    optimizer.update()\n",
    "    \n",
    "    print(loss.value())\n",
    "print(\"total time: \" + str(time.time() - epoch_start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching\n",
    "Batching your updates means that you consolidate a certain number of losses into a single value, then backpropagate over an average of the values. This has two affects on performance:\n",
    "\n",
    "1. Training could be a lot faster, especially with autobatching in DyNet. \n",
    "2. There are empirical changes in performance with lower or higher batch sizes. The batch size is a hyperparameter you can tune to get the best results in the end, and it depends a lot on the task you are using.\n",
    "\n",
    "The following code waits until a certain number of examples have been processed, and only then does an update. Importantly, we also turn on autobatching, so that intermediate computations will be batched automatically, making things faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "\n",
    "def epoch_train(examples):\n",
    "    epoch_start_time = time.time()\n",
    "    dy.renew_cg()\n",
    "    random.shuffle(examples)\n",
    "    current_losses = [ ]\n",
    "    for i, example in enumerate(examples):\n",
    "        loss = dy.pickneglogsoftmax(get_scores(example), example[\"label\"])\n",
    "        current_losses.append(loss)\n",
    "\n",
    "        if len(current_losses) >= BATCH_SIZE:\n",
    "            mean_loss = dy.esum(current_losses) / float(len(current_losses))\n",
    "            mean_loss.forward()\n",
    "            mean_loss.backward()\n",
    "            optimizer.update()\n",
    "            current_losses = [ ]\n",
    "            dy.renew_cg()\n",
    "    if current_losses:\n",
    "        mean_loss = dy.esum(current_losses) / float(len(current_losses))\n",
    "        mean_loss.forward()\n",
    "        mean_loss.backward()\n",
    "        optimizer.update()\n",
    "    print(\"total time: \" + str(time.time() - epoch_start_time))\n",
    "       \n",
    "epoch_train(train_examples[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write some code that trains for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 25\n",
    "\n",
    "max_accuracy = 0.\n",
    "best_epoch = 0\n",
    "start_time = time.time()\n",
    "for i in range(NUM_EPOCHS):\n",
    "    epoch_train(train_examples)\n",
    "    \n",
    "    accuracy = sum([float(evaluate(example)) for example in dev_examples]) / float(len(dev_examples))\n",
    "    print(\"epoch \" + str(i) + \" accuracy: \" + str(accuracy))\n",
    "    if accuracy > max_accuracy:\n",
    "        print(\"improved!\")\n",
    "        pc.save(\"model-epoch\" + str(i) + \".dy\")\n",
    "        best_epoch = i\n",
    "        max_accuracy = accuracy\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"total training time: \" + str(total_time) + \"; \" + str(float(total_time) / NUM_EPOCHS) + \" per epoch\")\n",
    "print(\"loading from model at epoch \" + str(best_epoch))\n",
    "pc.populate(\"model-epoch\" + str(best_epoch) + \".dy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has improved performance! Now we should do some analysis of its errors. \n",
    "\n",
    "## Evaluation and error analysis\n",
    "First, we will print 20 examples of random errors that the model made and see if we can identify why they made the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_examples = [example for example in dev_examples if not evaluate(example)]\n",
    "print(\"Error rate: \" + str(float(len(wrong_examples)) / len(dev_examples)))\n",
    "random.shuffle(wrong_examples)\n",
    "for example in wrong_examples[:10]:\n",
    "    print(str(example[\"label\"]) + \"\\t\" + \" \".join(example[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_examples = [example for example in train_examples if not evaluate(example)]\n",
    "print(\"Error rate: \" + str(float(len(wrong_examples)) / len(dev_examples)))\n",
    "random.shuffle(wrong_examples)\n",
    "for example in wrong_examples[:10]:\n",
    "    print(str(example[\"label\"]) + \"\\t\" + \" \".join(example[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_input(input_string):\n",
    "    example = {\"data\": nltk.word_tokenize(input_string.lower())}\n",
    "    return np.argmax(get_scores(example).value())\n",
    "\n",
    "evaluate_input(\"This movie is really bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_input(\"This movie made me feel happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What mistake was I making in terms of handling data?\n",
    "* How do we improve development / test performance?\n",
    "* Issues with the UNK token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
